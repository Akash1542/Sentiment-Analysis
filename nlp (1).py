# -*- coding: utf-8 -*-
"""NLP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rZufRYr6TO6zrDm954Fucf0sXEZDNjXR
"""

!pip install nltk
import nltk
nltk.download('stopwords')
nltk.download('punkt_tab')
import pandas as pd
import numpy as np
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import SnowballStemmer
from nltk import NaiveBayesClassifier, FreqDist
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split, KFold, cross_val_score
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Loading data
training_set = pd.read_csv("train.tsv", sep="\t")
testing_set = pd.read_csv("test.tsv", sep="\t")

# Step 1: Load and Preprocess Data
def clean_text(sentence, remove_stopwords=True, use_stemming=True, add_bigrams=True):
    """
    Preprocesses a single sentence:
    - Tokenization
    - Stopword removal
    - Stemming
    - Adding bigrams
    """
    stemmer = SnowballStemmer("english")
    stopword_list = set(stopwords.words("english"))

    if pd.isna(sentence):
        return []

    token_list = word_tokenize(sentence.lower())
    token_list = [word for word in token_list if word.isalnum()]

    if remove_stopwords:
        token_list = [word for word in token_list if word not in stopword_list]

    if use_stemming:
        token_list = [stemmer.stem(word) for word in token_list]

    if add_bigrams:
        token_list += [' '.join(gram) for gram in zip(token_list[:-1], token_list[1:])]

    return token_list


# Apply preprocessing
training_set['ProcessedText'] = training_set['Phrase'].apply(clean_text)

# Visualize sentiment distribution
training_set['Sentiment'].value_counts().plot(kind='bar', title="Sentiment Distribution", figsize=(8, 5))
plt.xlabel("Sentiment")
plt.ylabel("Frequency")
plt.show()

# Display raw vs processed text
print(training_set[['Phrase', 'ProcessedText']].head())

# Check for null values
print(f"Null values:\n{training_set.isnull().sum()}")

# Display most common words after preprocessing
all_words = [word for phrase in training_set['ProcessedText'] for word in phrase]
word_freq = FreqDist(all_words)
print(f"Most common words: {word_freq.most_common(10)}")

from nltk import NaiveBayesClassifier, classify
from sklearn.model_selection import KFold
from nltk.probability import FreqDist
import numpy as np

# Generate feature sets for Bag-of-Words
def create_features(words, most_common=1000):
    all_tokens = [word for phrase in words for word in phrase]
    token_frequency = FreqDist(all_words)
    common_words = set(word for word, freq in token_frequency.most_common(most_common))

    def word_features(phrase):
        return {word: (word in phrase) for word in common_words}

    return [word_features(phrase) for phrase in words]

# Extract processed phrases and labels
X_words = training_set['ProcessedText']
y_labels = training_set['Sentiment']

# Generate feature sets
features = create_features(X_words)
labeled_featuresets = list(zip(features, y_labels))

# Train and evaluate Naive Bayes Classifier
def train_and_evaluate_naive_bayes(labeled_featuresets, n_splits=5):
    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)
    accuracy_scores = []
    precision_scores = []
    recall_scores = []
    f1_scores = []

    for train_idx, test_idx in kfold.split(labeled_featuresets):
        train_set = [labeled_featuresets[i] for i in train_idx]
        test_set = [labeled_featuresets[i] for i in test_idx]

        classifier = NaiveBayesClassifier.train(train_set)

        # Evaluate on test set
        predictions = [classifier.classify(fs[0]) for fs in test_set]
        true_labels = [fs[1] for fs in test_set]

        # Metrics
        from sklearn.metrics import precision_recall_fscore_support, accuracy_score
        precision, recall, f1, _ = precision_recall_fscore_support(
            true_labels, predictions, average='weighted'
        )
        accuracy = accuracy_score(true_labels, predictions)

        accuracy_scores.append(accuracy)
        precision_scores.append(precision)
        recall_scores.append(recall)
        f1_scores.append(f1)

    print(f"Cross-Validation Results (n={n_splits}):")
    print(f"Accuracy: {np.mean(accuracy_scores):.4f}")
    print(f"Precision: {np.mean(precision_scores):.4f}")
    print(f"Recall: {np.mean(recall_scores):.4f}")
    print(f"F1-Score: {np.mean(f1_scores):.4f}")

    return classifier

# Train and evaluate
classifier = train_and_evaluate_naive_bayes(labeled_featuresets)

# Show most informative features
print("Most Informative Features:")
classifier.show_most_informative_features(10)

from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split

# Bag-of-Words: Word Frequency
vectorizer_freq = CountVectorizer(max_features=5000)
X_freq = vectorizer_freq.fit_transform(training_set['ProcessedText'].apply(lambda x: ' '.join(x)))

# Bag-of-Words: TF-IDF
vectorizer_tfidf = TfidfVectorizer(max_features=5000)
X_tfidf = vectorizer_tfidf.fit_transform(training_set['ProcessedText'].apply(lambda x: ' '.join(x)))

# Split data for evaluation
y = training_set['Sentiment']
X_freq_train, X_freq_test, y_train, y_test = train_test_split(X_freq, y, test_size=0.2, random_state=42)
X_tfidf_train, X_tfidf_test, _, _ = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)

# Logistic Regression on Word Frequency
print("Logistic Regression with Word Frequency")
logistic_freq = LogisticRegression(max_iter=1000)
logistic_freq.fit(X_freq_train, y_train)
y_pred_freq = logistic_freq.predict(X_freq_test)
print(classification_report(y_test, y_pred_freq))

# Logistic Regression on TF-IDF
print("Logistic Regression with TF-IDF")
logistic_tfidf = LogisticRegression(max_iter=1000)
logistic_tfidf.fit(X_tfidf_train, y_train)
y_pred_tfidf = logistic_tfidf.predict(X_tfidf_test)
print(classification_report(y_test, y_pred_tfidf))

import nltk

nltk.download('averaged_perceptron_tagger_eng')

import pandas as pd
import numpy as np
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import SnowballStemmer
from nltk import pos_tag
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC

# Step 1: Preprocessing Function
def clean_text(sentence, remove_stopwords=True, use_stemming=True, add_bigrams=True, handle_negation=True):
    stemmer = SnowballStemmer("english")
    stopword_list = set(stopwords.words("english"))

    if pd.isna(sentence):
        return []

    token_list = word_tokenize(sentence.lower())
    token_list = [word for word in token_list if word.isalnum()]

    if remove_stopwords:
        token_list = [word for word in token_list if word not in stopword_list]

    if use_stemming:
        token_list = [stemmer.stem(word) for word in token_list]

    if handle_negation:
        # Handle negations (e.g., "not good" -> "not_good_NEG")
        negation_tokens = []
        negation_flag = False
        for word in token_list:
            if word in ["not", "no", "never"]:
                negation_flag = True
            elif negation_flag:
                negation_tokens.append(word + "_NEG")
                negation_flag = False
            else:
                negation_tokens.append(word)
        token_list = negation_tokens

    if add_bigrams:
        token_list += [' '.join(gram) for gram in zip(token_list[:-1], token_list[1:])]

    return token_list

# Load and preprocess data
train_file_path = 'train.tsv'
training_set = pd.read_csv(train_file_path, sep='\t')
training_set['ProcessedText'] = training_set['Phrase'].apply(clean_text)

# Step 2: Feature Engineering
vectorizer_freq = CountVectorizer(max_features=50)
X_freq = vectorizer_freq.fit_transform(training_set['ProcessedText'].apply(lambda x: ' '.join(x)))

vectorizer_tfidf = TfidfVectorizer(max_features=50)
X_tfidf = vectorizer_tfidf.fit_transform(training_set['ProcessedText'].apply(lambda x: ' '.join(x)))

# Extract POS tags as features
def pos_tag_features(phrases):
    pos_tags = [' '.join(tag for _, tag in pos_tag(word_tokenize(phrase))) for phrase in phrases]
    vectorizer_pos = CountVectorizer(max_features=1000)
    return vectorizer_pos.fit_transform(pos_tags)

X_pos = pos_tag_features(training_set['Phrase'])

# Combine features
from scipy.sparse import hstack
X_combined = hstack([X_freq, X_pos])

y = training_set['Sentiment']
X_freq_train, X_freq_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)

# Step 3: Train and Evaluate Classifiers
def evaluate_classifier(model, X_train, X_test, y_train, y_test):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    print(f"Results for {model.__class__.__name__}:")
    print(classification_report(y_test, y_pred))

# Logistic Regression
logistic_model = LogisticRegression(max_iter=1000)
evaluate_classifier(logistic_model, X_freq_train, X_freq_test, y_train, y_test)

# Multinomial Naive Bayes
naive_bayes_model = MultinomialNB()
evaluate_classifier(naive_bayes_model, X_freq_train, X_freq_test, y_train, y_test)

# Support Vector Machine (SVM)
svm_model = SVC(kernel='linear', max_iter=1000)
evaluate_classifier(svm_model, X_freq_train, X_freq_test, y_train, y_test)

# Experiment with TF-IDF
X_tfidf_train, X_tfidf_test, _, _ = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)
evaluate_classifier(logistic_model, X_tfidf_train, X_tfidf_test, y_train, y_test)

# Save combined features and labels
output_file = 'combined_features.csv'
pd.DataFrame.sparse.from_spmatrix(X_combined).to_csv(output_file, index=False)
print(f"Features saved to {output_file}")

# Enhanced Visualization for Model Performance Metrics
import matplotlib.pyplot as plt
import numpy as np

# Data for the models
model_results = {
    "Logistic Regression (BoW)": {
        "Accuracy": 0.62,
        "Precision": 0.56,
        "Recall": 0.45,
        "F1-Score": 0.48
    },
    "Multinomial Naive Bayes (BoW)": {
        "Accuracy": 0.58,
        "Precision": 0.47,
        "Recall": 0.50,
        "F1-Score": 0.48
    },
    "SVM (BoW)": {
        "Accuracy": 0.14,
        "Precision": 0.24,
        "Recall": 0.25,
        "F1-Score": 0.17
    },
    "Logistic Regression (TF-IDF)": {
        "Accuracy": 0.62,
        "Precision": 0.58,
        "Recall": 0.41,
        "F1-Score": 0.45
    }
}

# Extracting data for visualization
metrics = ["Accuracy", "Precision", "Recall", "F1-Score"]
data = {metric: [model_results[model][metric] for model in model_results] for metric in metrics}
models = list(model_results.keys())

# Bar chart configuration
x = np.arange(len(models))
bar_width = 0.2

fig, ax = plt.subplots(figsize=(14, 8))

colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']  # Distinct colors for each metric

for i, metric in enumerate(metrics):
    ax.bar(x + i * bar_width, data[metric], width=bar_width, label=metric, color=colors[i])

# Customizing the plot for better readability and aesthetics
ax.set_xlabel("Models", fontsize=14, labelpad=10)
ax.set_ylabel("Scores", fontsize=14, labelpad=10)
ax.set_title("Performance Metrics for Sentiment Analysis Models", fontsize=18, pad=20)
ax.set_xticks(x + bar_width * 1.5)
ax.set_xticklabels(models, rotation=15, fontsize=12)
ax.legend(title="Metrics", fontsize=12, title_fontsize=14, loc='upper left')
ax.grid(axis='y', linestyle='--', alpha=0.7)

# Annotating bars with their values
for i, metric in enumerate(metrics):
    for j, score in enumerate(data[metric]):
        ax.text(x[j] + i * bar_width, score + 0.01, f"{score:.2f}", ha='center', va='bottom', fontsize=10)

plt.tight_layout()
plt.show()

import nltk
nltk.download('vader_lexicon')

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split

# Tokenize and pad sequences
tokenizer = Tokenizer(num_words=5000)
tokenizer.fit_on_texts(train_data['ProcessedPhrase'].apply(lambda x: ' '.join(x)))
X_sequences = tokenizer.texts_to_sequences(train_data['ProcessedPhrase'].apply(lambda x: ' '.join(x)))
X_padded = pad_sequences(X_sequences, maxlen=50)

# Prepare data for training
y = train_data['Sentiment']
X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=42)

# Build the LSTM model
model = Sequential([
    Embedding(input_dim=5000, output_dim=128, input_length=50),
    Bidirectional(LSTM(64, return_sequences=True)),
    Dropout(0.3),
    LSTM(64),
    Dense(64, activation='relu'),
    Dropout(0.3),
    Dense(5, activation='softmax')
])

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])
model.summary()

# Train the model
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=64)

# Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test)
print(f"LSTM Model Accuracy: {accuracy:.4f}")

from imblearn.over_sampling import SMOTE
from sklearn.feature_extraction.text import CountVectorizer

# Vectorize data for SMOTE
vectorizer = CountVectorizer(max_features=5000)
X_vectorized = vectorizer.fit_transform(train_data['ProcessedPhrase'].apply(lambda x: ' '.join(x)))

# Apply SMOTE
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_vectorized, train_data['Sentiment'])

# Train Logistic Regression on augmented data
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)
model = LogisticRegression(max_iter=10)
model.fit(X_train, y_train)

from imblearn.over_sampling import SMOTE
from sklearn.feature_extraction.text import CountVectorizer

# Vectorize data for SMOTE
vectorizer = CountVectorizer(max_features=5000)
X_vectorized = vectorizer.fit_transform(train_data['ProcessedPhrase'].apply(lambda x: ' '.join(x)))

# Apply SMOTE
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_vectorized, train_data['Sentiment'])

# Train Logistic Regression on augmented data
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
print("Logistic Regression with SMOTE:")
print(classification_report(y_test, y_pred))

from sklearn.ensemble import StackingClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression

# Define base models
base_models = [
    ('nb', MultinomialNB()),
    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),
    ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42))
]

# Stacking Classifier
stack_model = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression())

# Resample X_freq_train to match y_train using SMOTE
from imblearn.over_sampling import SMOTE
from sklearn.feature_extraction.text import CountVectorizer
# Assuming X_freq is your original feature matrix before SMOTE
smote = SMOTE(random_state=42)
X_freq_resampled, y_resampled = smote.fit_resample(X_freq, y)  # y is your original target variable

# Now split the resampled data
X_freq_train, X_freq_test, y_train, y_test = train_test_split(X_freq_resampled, y_resampled, test_size=0.2, random_state=42)


# Fit the StackingClassifier with the resampled data
stack_model.fit(X_freq_train, y_train)

# Evaluate the stacking model
y_pred = stack_model.predict(X_freq_test)
print("Stacking Model:")
print(classification_report(y_test, y_pred))

from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import cross_val_score
from nltk.sentiment import SentimentIntensityAnalyzer
from scipy.sparse import hstack
from sklearn.preprocessing import StandardScaler

# Add Sentiment Lexicon Features (VADER)
sia = SentimentIntensityAnalyzer()

def sentiment_features(phrases):
    sentiment_scores = []
    for phrase in phrases:
        scores = sia.polarity_scores(phrase)
        sentiment_scores.append([scores['pos'], scores['neu'], scores['neg'], scores['compound']])
    return np.array(sentiment_scores)

# Generate sentiment scores
sentiment_scores_train = sentiment_features(training_set['Phrase'])
sentiment_scores_combined = hstack([X_combined, sentiment_scores_train])

# Scale the features
scaler = StandardScaler(with_mean=False)  # Use with_mean=False for sparse matrices
X_scaled = scaler.fit_transform(sentiment_scores_combined)

# Add Cross-Validation Evaluation
def evaluate_with_cross_validation(model, X, y, cv=5):
    scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')
    print(f"Cross-Validation Results for {model.__class__.__name__}:")
    print(f"Mean Accuracy: {np.mean(scores):.4f}, Std Dev: {np.std(scores):.4f}")

# Experiment 1: Logistic Regression with Sentiment Lexicon Features
print("Logistic Regression with Sentiment Features")
logistic_model = LogisticRegression(max_iter=1000)  # Increase max_iter
evaluate_with_cross_validation(logistic_model, X_scaled, y)

# Experiment 2: Random Forest Classifier
print("Random Forest Classifier")
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
evaluate_with_cross_validation(rf_model, X_scaled, y)

# Experiment 3: Gradient Boosting Classifier
print("Gradient Boosting Classifier")
gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)
evaluate_with_cross_validation(gb_model, X_scaled, y)

# Experiment 4: Combined Features with Sentiment Scores and POS Tags
print("Random Forest with Combined Features")
rf_with_sentiment = RandomForestClassifier(n_estimators=100, random_state=42)
evaluate_with_cross_validation(rf_with_sentiment, X_scaled, y)

# Experiment 5: SVM with Preprocessed Features
print("SVM with Preprocessed Features")
svm_model_scaled = SVC(kernel='linear', max_iter=1000)  # Increase max_iter
evaluate_with_cross_validation(svm_model_scaled, X_scaled, y)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Vectorize the text using Bag-of-Words
vectorizer = CountVectorizer(max_features=5000)
X = vectorizer.fit_transform(train_data['ProcessedPhrase'].apply(lambda x: ' '.join(x)))

# Split the data
y = train_data['Sentiment']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train KNN classifier
k = 5  # Choose number of neighbors
knn_model = KNeighborsClassifier(n_neighbors=k)
knn_model.fit(X_train, y_train)

# Evaluate the model
from sklearn.neighbors import KNeighborsClassifier
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Vectorize the text using Bag-of-Words
vectorizer = CountVectorizer(max_features=5000)
X = vectorizer.fit_transform(train_data['ProcessedPhrase'].apply(lambda x: ' '.join(x)))

# Split the data
y = train_data['Sentiment']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train KNN classifier
k = 5  # Choose number of neighbors
knn_model = KNeighborsClassifier(n_neighbors=k)
knn_model.fit(X_train, y_train)

# Evaluate the model
y_pred = knn_model.predict(X_test)
print(f"Classification Report for KNN (k={k}):")
print(classification_report(y_test, y_pred))

import matplotlib.pyplot as plt
import pandas as pd

# Results data
models = [
    "Logistic Regression",
    "Random Forest Classifier",
    "Gradient Boosting Classifier",
    "Random Forest with Combined Features",
    "SVM with Preprocessed Features"
]

accuracies = [0.5634, 0.5628, 0.5749, 0.5628, 0.1955]
std_devs = [0.0078, 0.0061, 0.0066, 0.0061, 0.0119]

# Create a DataFrame for better visualization
results_df = pd.DataFrame({
    "Model": models,
    "Mean Accuracy": accuracies,
    "Std Dev": std_devs
})

# Visualization
plt.figure(figsize=(10, 6))
plt.barh(results_df["Model"], results_df["Mean Accuracy"], xerr=results_df["Std Dev"], color="skyblue", edgecolor="black")
plt.xlabel("Mean Accuracy")
plt.title("Model Performance with Sentiment Lexicon Features")
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.tight_layout()

# Show the chart
plt.show()

from sklearn.metrics import ConfusionMatrixDisplay
import matplotlib.pyplot as plt

rf_model.fit(X_freq_train, y_train)
# Assuming rf_model is fitted
y_pred_rf = rf_model.predict(X_freq_test)

# Plot Confusion Matrix
print("Random Forest Confusion Matrix")
ConfusionMatrixDisplay.from_estimator(
    rf_model, X_freq_test, y_test,
    display_labels=["Negative", "Somewhat Negative", "Neutral", "Somewhat Positive", "Positive"],
    cmap=plt.cm.Blues
)
plt.show()

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Train Gradient Boosting model (ensure the model is fitted)
gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)
gb_model.fit(X_freq_train, y_train)

# Predictions for Gradient Boosting
y_pred_gb = gb_model.predict(X_freq_test)

# Plot Confusion Matrix for Gradient Boosting
print("Gradient Boosting Confusion Matrix")
# Use ConfusionMatrixDisplay.from_predictions instead of plot_confusion_matrix
ConfusionMatrixDisplay.from_predictions(
    y_test, y_pred_gb,
    display_labels=["Negative", "Somewhat Negative", "Neutral", "Somewhat Positive", "Positive"],
    cmap=plt.cm.Blues
)
plt.show()

from sklearn.metrics import ConfusionMatrixDisplay
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

print("Logistic Regression Confusion Matrix")
X_freq_train, X_freq_test, y_train, y_test = train_test_split(X_freq, y, test_size=0.2, random_state=42)

# Instantiate and train the logistic regression model
logistic_model = LogisticRegression(max_iter=1000)
logistic_model.fit(X_freq_train, y_train)

# Make predictions
y_pred_logistic = logistic_model.predict(X_freq_test)

# Now use ConfusionMatrixDisplay to plot the confusion matrix
ConfusionMatrixDisplay.from_predictions(
    y_test, y_pred_logistic,
    display_labels=["Negative", "Somewhat Negative", "Neutral", "Somewhat Positive", "Positive"],
    cmap=plt.cm.Blues
).plot()

plt.show()

# Import the ConfusionMatrixDisplay class
from sklearn.metrics import ConfusionMatrixDisplay
# Confusion matrix
cm_smote = confusion_matrix(y_test, y_pred)
ConfusionMatrixDisplay(confusion_matrix=cm_smote, display_labels=["Negative", "Somewhat Negative", "Neutral", "Somewhat Positive", "Positive"]).plot(cmap=plt.cm.Blues)

plt.title("Confusion Matrix for Logistic Regression with SMOTE")
plt.show()

# Confusion matrix
cm_stack = confusion_matrix(y_test, y_pred)
ConfusionMatrixDisplay(confusion_matrix=cm_stack, display_labels=["Negative", "Somewhat Negative", "Neutral", "Somewhat Positive", "Positive"]).plot(cmap=plt.cm.Blues)

plt.title("Confusion Matrix for Stacking Classifier")
plt.show()

# Generate Confusion Matrix
ConfusionMatrixDisplay.from_estimator(
    knn_model, X_test, y_test,
    display_labels=["Negative", "Somewhat Negative", "Neutral", "Somewhat Positive", "Positive"],
    cmap=plt.cm.Blues
).plot()
plt.title(f"Confusion Matrix for KNN (k={k})")
plt.show()

from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction.text import CountVectorizer
import pandas as pd

# Load data
train_file_path = 'train.tsv'
test_file_path = 'test.tsv'

training_set = pd.read_csv(train_file_path, sep='\t')
testing_set = pd.read_csv(test_file_path, sep='\t')

# Preprocess data
training_set['ProcessedText'] = training_set['Phrase'].apply(clean_text)
testing_set['ProcessedText'] = testing_set['Phrase'].apply(clean_text)

# Combine data for consistent vocabulary in CountVectorizer
all_phrases = pd.concat([
    training_set['ProcessedText'],
    testing_set['ProcessedText']
])

# Fit CountVectorizer on combined data
vectorizer_freq = CountVectorizer(max_features=5000)
vectorizer_freq.fit(all_phrases.apply(lambda x: ' '.join(x)))

# Transform training and test data using the same vectorizer
X_freq_train = vectorizer_freq.transform(training_set['ProcessedText'].apply(lambda x: ' '.join(x)))
X_freq_test = vectorizer_freq.transform(testing_set['ProcessedText'].apply(lambda x: ' '.join(x)))

# Train Random Forest model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_freq_train, training_set['Sentiment'])

# Predict sentiments for test data
testing_set['Sentiment'] = rf_model.predict(X_freq_test)

# Save predictions to a CSV file
testing_set[['PhraseId', 'Sentiment']].to_csv('test_predictions_using_RF.csv', index=False)
print("Predictions saved to test_predictions_using_RF.csv")

from sklearn.ensemble import GradientBoostingClassifier

## Train Gradient Boosting model
gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)
gb_model.fit(X_freq_train, training_set['Sentiment'])

# Predict sentiments for test data
testing_set['Sentiment'] = gb_model.predict(X_freq_test)

# Save predictions to a CSV file
testing_set[['PhraseId', 'Sentiment']].to_csv('test_predictions1.csv', index=False)
print("Predictions saved to test_predictions1.csv")